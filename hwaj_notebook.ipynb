{"cells":[{"cell_type":"code","source":["!pip install transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFxdOPr5ZYEH","executionInfo":{"status":"ok","timestamp":1648839744870,"user_tz":240,"elapsed":12027,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"f37b05c7-ddb3-4d2b-f417-daee6b509534"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 4.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 48.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 35.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mUugRCuIWHIx","executionInfo":{"status":"ok","timestamp":1648848502383,"user_tz":240,"elapsed":296,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7VHRrFQWM-P","executionInfo":{"status":"ok","timestamp":1648848504842,"user_tz":240,"elapsed":1535,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"166b5f33-ed1b-4fb3-cf6a-50a737bd6147"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 2022WI folder and put all the files under A4 folder, then \"2022WI/A4\"\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"487/propaganda_detection\"\n","GOOGLE_DRIVE_PATH = os.path.join(\"drive\", \"My Drive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","\n","# Add to sys so we can import .py files.\n","sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZpZzb7OdTgl","executionInfo":{"status":"ok","timestamp":1648848505558,"user_tz":240,"elapsed":7,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"bb545d60-31e0-4745-9aa7-92464f690663"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['readme.md', 'data_logical_fallacy', 'data_proppy', 'ingest_data_test.ipynb', 'naieve_bayes_baseline.ipynb', 'dataset.py', '.git', 'model.py', 'Copy of ingest_data_test.ipynb', '__pycache__', '.idea']\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"v-rDS8bfWHI2","executionInfo":{"status":"ok","timestamp":1648848525683,"user_tz":240,"elapsed":7360,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}}},"outputs":[],"source":["from dataset import FallacyDataset\n","from pathlib import Path\n","\n","# train_dataset = ProppyDataset(Path(GOOGLE_DRIVE_PATH) / \"data_proppy\" / \"proppy_1.0.train.tsv\")\n","# test_dataset = ProppyDataset(Path(GOOGLE_DRIVE_PATH) / \"data_proppy\" / \"proppy_1.0.test.tsv\")\n","\n","train_dataset = FallacyDataset(Path(GOOGLE_DRIVE_PATH) / \"data_logical_fallacy\" / \"edu_train.csv\")\n","test_dataset = FallacyDataset(Path(GOOGLE_DRIVE_PATH) / \"data_logical_fallacy\" / \"edu_test.csv\")"]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDmqkSUVovjH","executionInfo":{"status":"ok","timestamp":1648848463767,"user_tz":240,"elapsed":297,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"e702fd40-8463-4163-b481-7bc4dd754c59"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stderr","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"]},{"output_type":"execute_result","data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'input_ids': tensor([  101,  2194,  1005,  1055, 14558,  1000,  5987,  2062,  1012,  3477,\n","          2625,  1012,  1000,   102,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'label': 0,\n"," 'text': 'company\\'s slogan \"Expect More. Pay Less.\"'}"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","source":["import numpy as np\n","np.unique([x['label'] for x in train_dataset], return_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DoPGpPgQ_mLp","executionInfo":{"status":"ok","timestamp":1648848530752,"user_tz":240,"elapsed":313,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"764a7b43-ff58-42a8-f47b-e5cce4100a14"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]),\n"," array([130, 174, 158, 134, 114, 319, 225, 106,  39, 121, 106, 112, 110]))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTLrbLyzWHI3","executionInfo":{"status":"ok","timestamp":1648849165452,"user_tz":240,"elapsed":286,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"9c9b47d3-f1b6-4134-e8dd-88f4bc1ddb0b"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from model import model\n","from transformers import Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n","    acc = accuracy_score(labels, preds)\n","    # print(pred.label_ids)\n","    # print(pred.predictions)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=10,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    warmup_steps=500,\n","    learning_rate=1e-4,\n","    weight_decay=0,\n","    evaluation_strategy='epoch',\n","    logging_dir='./logs',\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset\n",")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TlMjhVzIWHI3","executionInfo":{"status":"ok","timestamp":1648850148324,"user_tz":240,"elapsed":94387,"user":{"displayName":"Jensen Hwa","userId":"05254362443363140054"}},"outputId":"4acbd9a5-3c33-408f-98b7-fef08c929e2b"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1848\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2310\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2086' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2086/2310 14:44 < 01:35, 2.35 it/s, Epoch 9.03/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.500315</td>\n","      <td>0.176667</td>\n","      <td>0.122529</td>\n","      <td>0.138152</td>\n","      <td>0.158795</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.952849</td>\n","      <td>0.203333</td>\n","      <td>0.152334</td>\n","      <td>0.150170</td>\n","      <td>0.161479</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.909800</td>\n","      <td>4.004936</td>\n","      <td>0.183333</td>\n","      <td>0.149625</td>\n","      <td>0.154409</td>\n","      <td>0.160655</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.909800</td>\n","      <td>5.155292</td>\n","      <td>0.183333</td>\n","      <td>0.153141</td>\n","      <td>0.152476</td>\n","      <td>0.189930</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.530100</td>\n","      <td>6.038149</td>\n","      <td>0.183333</td>\n","      <td>0.142581</td>\n","      <td>0.144152</td>\n","      <td>0.160623</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.530100</td>\n","      <td>6.807018</td>\n","      <td>0.170000</td>\n","      <td>0.136886</td>\n","      <td>0.137130</td>\n","      <td>0.158430</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.112900</td>\n","      <td>6.920737</td>\n","      <td>0.183333</td>\n","      <td>0.144378</td>\n","      <td>0.145354</td>\n","      <td>0.161077</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.112900</td>\n","      <td>6.960622</td>\n","      <td>0.193333</td>\n","      <td>0.158055</td>\n","      <td>0.161635</td>\n","      <td>0.170068</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.022100</td>\n","      <td>7.079723</td>\n","      <td>0.183333</td>\n","      <td>0.151939</td>\n","      <td>0.154322</td>\n","      <td>0.166285</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[ 0.4111157  -0.05412817  0.36585614 ... -0.4129431  -0.4097272\n","  -0.50862986]\n"," [-0.07252732 -0.12364152  0.08340665 ... -0.3960539   0.08798622\n","  -0.8607999 ]\n"," [ 0.21768552  0.55497867  0.54024076 ... -0.35514107 -0.22739658\n","  -0.96981597]\n"," ...\n"," [ 0.3100702   0.34860516  0.7745706  ... -0.5433433  -0.4041368\n","  -0.78037745]\n"," [ 0.408443    0.58870596  0.18999366 ... -0.46754676 -0.32016098\n","  -0.01354949]\n"," [ 0.00178758 -0.6917257   0.076148   ...  0.23578477  0.08918598\n","  -1.1414108 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-0.7687296  -0.72230893 -0.74839634 ... -0.34187976 -1.1244904\n","  -0.72509223]\n"," [-1.2768407  -0.22751202 -1.1560578  ... -0.8497925   0.26312336\n","  -0.93905103]\n"," [-0.46812317  3.7296798  -0.18754563 ... -1.0202485  -0.25631276\n","  -1.2570955 ]\n"," ...\n"," [-1.1185235  -0.01267305  2.275752   ... -0.3566501  -1.0006034\n","  -1.6488849 ]\n"," [-0.5248756   3.0108912  -1.3746625  ... -0.4553742  -0.15356414\n","  -1.2653095 ]\n"," [-1.0439758  -1.1836452   0.21325612 ...  1.4251763  -0.01370319\n","  -1.9156691 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.2681437  -0.8138132  -1.0762352  ... -0.69594824 -1.1510063\n","  -0.5548081 ]\n"," [-1.720861   -1.6540537  -2.0967476  ... -0.97548467  2.458002\n","  -1.3340147 ]\n"," [-1.0657858   3.6359732  -0.21164268 ... -2.013937   -1.0837026\n","  -1.4193513 ]\n"," ...\n"," [-0.627169    0.06018163  2.3106527  ... -1.7717942  -1.4865884\n","  -1.3741367 ]\n"," [-0.6442338   1.6978221  -0.9900656  ... -1.4443331  -1.3852152\n","  -1.6565214 ]\n"," [-1.4359401  -1.6631207  -1.0515448  ...  1.8070171  -0.01735753\n","  -2.8126302 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.4705303  -0.87087965 -0.8856161  ... -1.2164778  -1.7509247\n","   0.35735252]\n"," [-1.6948507  -1.8814193  -2.170915   ... -1.0930178   0.4811145\n","   2.5066178 ]\n"," [-2.437006    2.2808967   2.693225   ... -1.9836054  -1.6741521\n","  -1.0502764 ]\n"," ...\n"," [-0.7472203  -1.0576203   5.6092854  ... -1.764997   -1.5895351\n","  -0.4206279 ]\n"," [-1.7846141   1.9794382  -1.1839821  ... -1.6345505  -1.935506\n","  -1.0007143 ]\n"," [-1.8364341  -2.6296947  -0.16239165 ...  1.846384    0.03915635\n","  -3.434564  ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.4914814  -1.7215805  -1.6309812  ... -1.3813814  -2.7034945\n","  -1.0370501 ]\n"," [-1.9779538  -3.4311903  -2.7721975  ... -1.5567452   3.7742074\n","  -0.46184114]\n"," [-0.6197424   0.62304413 -0.8457219  ... -2.5341947  -1.8235835\n","  -1.0838318 ]\n"," ...\n"," [-0.98621285  0.3235976   2.0802457  ... -2.3431864  -2.5856028\n","  -1.2462895 ]\n"," [-0.7531143   1.7050453  -1.256172   ... -2.2467053  -2.2443156\n","  -1.0381843 ]\n"," [-1.7589177  -1.7414787  -0.33876154 ...  0.20043407 -1.5476178\n","  -2.7927291 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.7559317  -1.4012738  -1.9979619  ... -1.4209167  -2.7018735\n","  -1.1720346 ]\n"," [-1.7210075  -3.403296   -2.6327558  ... -1.6307449   7.497787\n","  -0.28977093]\n"," [-1.1778005   0.2227143  -1.2382189  ... -3.0462835  -1.5330452\n","  -1.7997078 ]\n"," ...\n"," [-0.90856135 -1.2261422  -0.06961882 ... -2.1881776  -2.6182878\n","  -1.6411688 ]\n"," [-0.9750172   3.1575508  -1.7147212  ... -2.7222607  -2.0662076\n","  -1.047939  ]\n"," [-2.2597468  -2.1323333  -0.42328092 ... -0.82427335 -0.63054514\n","  -2.928245  ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.5581686  -1.0830929  -1.7847059  ... -1.5495332  -2.8958728\n","  -1.1214025 ]\n"," [-1.9489844  -3.286504   -2.782292   ... -1.4402022   6.911361\n","  -0.15305717]\n"," [-1.4237767   3.0279279  -0.36071134 ... -3.303251   -2.4775162\n","  -1.4045068 ]\n"," ...\n"," [-0.8972708  -0.5058919   1.6649153  ... -2.5087762  -3.1363912\n","  -1.578751  ]\n"," [-0.92431396  3.803615   -1.1507294  ... -3.0623443  -2.9432223\n","  -1.6197989 ]\n"," [-2.196346   -2.3834548  -0.66776764 ... -0.2908843  -1.3002738\n","  -3.243711  ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.6950216  -1.1938795  -1.6170379  ... -1.6719887  -3.1372688\n","  -1.1986418 ]\n"," [-2.6314523  -3.3747778  -3.2895396  ... -1.8342485   6.208697\n","  -0.77852213]\n"," [-1.566928    3.1153543  -0.37545845 ... -3.5217428  -2.9018166\n","  -1.4260485 ]\n"," ...\n"," [-0.9498503  -0.5544532   1.0286125  ... -2.645708   -3.2786665\n","  -1.6329833 ]\n"," [-1.5508513   4.0549436  -0.9156166  ... -2.9639523  -3.2963495\n","  -1.7328173 ]\n"," [-2.2713816  -2.3969984  -0.65985674 ... -0.4952667  -1.6437812\n","  -3.2660108 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n","***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.7260798  -1.3288373  -1.7631832  ... -1.8148572  -3.2147272\n","  -1.3072913 ]\n"," [-2.5803275  -3.5514865  -3.2937999  ... -1.9908574   6.675508\n","  -0.9087595 ]\n"," [-1.7350861   2.607011   -0.68731195 ... -3.5861108  -2.8185942\n","  -1.5121027 ]\n"," ...\n"," [-0.94695216 -0.8983747   0.6349592  ... -2.6818697  -3.245153\n","  -1.567055  ]\n"," [-1.6264311   3.5953934  -1.3148221  ... -3.056818   -3.2828732\n","  -1.7948459 ]\n"," [-2.367909   -2.5400927  -0.8481848  ... -0.53825635 -1.4997555\n","  -3.4690766 ]]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["drive/My Drive/487/propaganda_detection/dataset.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2310/2310 16:19, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.500315</td>\n","      <td>0.176667</td>\n","      <td>0.122529</td>\n","      <td>0.138152</td>\n","      <td>0.158795</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.952849</td>\n","      <td>0.203333</td>\n","      <td>0.152334</td>\n","      <td>0.150170</td>\n","      <td>0.161479</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.909800</td>\n","      <td>4.004936</td>\n","      <td>0.183333</td>\n","      <td>0.149625</td>\n","      <td>0.154409</td>\n","      <td>0.160655</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.909800</td>\n","      <td>5.155292</td>\n","      <td>0.183333</td>\n","      <td>0.153141</td>\n","      <td>0.152476</td>\n","      <td>0.189930</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.530100</td>\n","      <td>6.038149</td>\n","      <td>0.183333</td>\n","      <td>0.142581</td>\n","      <td>0.144152</td>\n","      <td>0.160623</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.530100</td>\n","      <td>6.807018</td>\n","      <td>0.170000</td>\n","      <td>0.136886</td>\n","      <td>0.137130</td>\n","      <td>0.158430</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.112900</td>\n","      <td>6.920737</td>\n","      <td>0.183333</td>\n","      <td>0.144378</td>\n","      <td>0.145354</td>\n","      <td>0.161077</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.112900</td>\n","      <td>6.960622</td>\n","      <td>0.193333</td>\n","      <td>0.158055</td>\n","      <td>0.161635</td>\n","      <td>0.170068</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.022100</td>\n","      <td>7.079723</td>\n","      <td>0.183333</td>\n","      <td>0.151939</td>\n","      <td>0.154322</td>\n","      <td>0.166285</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.022100</td>\n","      <td>7.170796</td>\n","      <td>0.176667</td>\n","      <td>0.145138</td>\n","      <td>0.144581</td>\n","      <td>0.161819</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 300\n","  Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["[ 0  1  2  3  1  0  0  1  4  5  3  1  6  7  1  8  7  2  6  8  5  7  9  5\n","  0  9  6  6  1  6  1  5  5  4 10  9  3  7  1  7  4  8  6  8  7 10  8  6\n","  4  2  5  1 10 11  9  5  8  1  1 12  2  1  6 12  8  6  7  9  8  4 12  4\n","  7  9  6  8  7  2 12  8  2  2 10  6 10 12  1  6  0  6 12  3  4  4  6  3\n","  7 10  9  3  6 10  6  2  1  3  0  0  3  5  8  2  1  1  1 12 10  9  3  6\n","  2  5  1  1  8  9  6 11  1  4  9  1  7  4  1  2  1  6  1  6  1  0  6  1\n","  1  9  1  7  9  0  4  6  1  3  6  7  4  6  7  9  9  6 10  1  1  6  0  4\n","  0  1 10 10  2  3  1  7  1  7  9  3  9  0  5  9 12  7 10  6  1  1  5  9\n","  0 10 11  7  1  1  1  1  6  1 10  7  9  7  3  6  7  1  7  4  7  0  4  6\n","  9  6  7 12  1  3  6  1  8 10 11  6  1 10  8 10  1  2  5 10 10  9  5  6\n"," 10  1  9  9  3  5  1  0  1  6  5 10  9 12  8  1  4 12  0  3  1  0  5  7\n","  0  5  2  1  0 10  1 11 12  3 10  6  1  4  7  1  0  1  3  1  6  6  6  1\n","  1  6  7  1  7  6  5  7  0  7  1  5]\n","[[-1.7013587  -1.4184573  -1.7441583  ... -1.8740095  -3.2402468\n","  -1.3617852 ]\n"," [-2.4888148  -3.634146   -3.2024317  ... -1.9889294   7.0209746\n","  -0.9928793 ]\n"," [-1.5566816   2.0361328  -0.59416705 ... -3.6166232  -2.776702\n","  -1.5270125 ]\n"," ...\n"," [-0.8454844  -1.1121252   0.7811289  ... -2.6832078  -3.234882\n","  -1.5860436 ]\n"," [-1.475038    2.9248927  -1.3509364  ... -3.1171553  -3.2755892\n","  -1.8396957 ]\n"," [-2.3753889  -2.638864   -0.8088799  ... -0.5683801  -1.4363263\n","  -3.5471241 ]]\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2310, training_loss=0.5591705712405118, metrics={'train_runtime': 979.9779, 'train_samples_per_second': 18.858, 'train_steps_per_second': 2.357, 'total_flos': 1138159578790080.0, 'train_loss': 0.5591705712405118, 'epoch': 10.0})"]},"metadata":{},"execution_count":9}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-C_Ji4SWHI4","executionInfo":{"status":"ok","timestamp":1648672772742,"user_tz":240,"elapsed":420,"user":{"displayName":"Safiyyah Ahmed","userId":"16102441518069447402"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3aecd7eb-3e75-4997-db0e-66256ab885c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Mar 30 20:39:32 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    25W /  70W |   4854MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":[""],"metadata":{"id":"8nGkqh0ljepu"},"execution_count":null,"outputs":[]}],"metadata":{"interpreter":{"hash":"28584a04334ae809113f3de0b099234fabcb50b20581a378ae9cc73c9f7a5983"},"kernelspec":{"display_name":"Python 3.9.7 ('eecs_nlp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"colab":{"name":"Copy of ingest_data_test.ipynb","provenance":[{"file_id":"1ZMCVyndRO03hgsUpjPXUr7WXE-sF3IQe","timestamp":1648837175912}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}